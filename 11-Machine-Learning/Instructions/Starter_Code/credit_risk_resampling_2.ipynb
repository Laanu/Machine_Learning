{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Resampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = [ \"loan_amnt\", \"int_rate\", \"total_pymnt_inv\",\"total_pymnt\",\"total_rec_prncp\",\"out_prncp_inv\",\"out_prncp\",\"last_pymnt_amnt\",\"total_rec_int\",\"loan_status\"]\n",
    "   \n",
    "\n",
    "target = [\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   loan_amnt  int_rate  total_pymnt_inv   total_pymnt  total_rec_prncp  \\\n",
       "0    35000.0    0.1308         35016.53  35016.528333         35000.00   \n",
       "1    20000.0    0.2250           719.00    719.000000           569.00   \n",
       "2    10500.0    0.1719           355.29    355.290000           295.13   \n",
       "3    25000.0    0.2000           873.53    873.530000           706.87   \n",
       "4    20000.0    0.2000           485.44    485.440000           363.21   \n",
       "\n",
       "   out_prncp_inv  out_prncp  last_pymnt_amnt  total_rec_int loan_status  \n",
       "0           0.00       0.00         35067.40          16.53  Fully Paid  \n",
       "1       19431.00   19431.00           769.00         150.00    low_risk  \n",
       "2       10204.87   10204.87           375.35          60.16    low_risk  \n",
       "3       24293.13   24293.13           929.09         166.66    low_risk  \n",
       "4       19636.79   19636.79           529.88         122.23    low_risk  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>total_pymnt_inv</th>\n      <th>total_pymnt</th>\n      <th>total_rec_prncp</th>\n      <th>out_prncp_inv</th>\n      <th>out_prncp</th>\n      <th>last_pymnt_amnt</th>\n      <th>total_rec_int</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35000.0</td>\n      <td>0.1308</td>\n      <td>35016.53</td>\n      <td>35016.528333</td>\n      <td>35000.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>35067.40</td>\n      <td>16.53</td>\n      <td>Fully Paid</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20000.0</td>\n      <td>0.2250</td>\n      <td>719.00</td>\n      <td>719.000000</td>\n      <td>569.00</td>\n      <td>19431.00</td>\n      <td>19431.00</td>\n      <td>769.00</td>\n      <td>150.00</td>\n      <td>low_risk</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10500.0</td>\n      <td>0.1719</td>\n      <td>355.29</td>\n      <td>355.290000</td>\n      <td>295.13</td>\n      <td>10204.87</td>\n      <td>10204.87</td>\n      <td>375.35</td>\n      <td>60.16</td>\n      <td>low_risk</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25000.0</td>\n      <td>0.2000</td>\n      <td>873.53</td>\n      <td>873.530000</td>\n      <td>706.87</td>\n      <td>24293.13</td>\n      <td>24293.13</td>\n      <td>929.09</td>\n      <td>166.66</td>\n      <td>low_risk</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20000.0</td>\n      <td>0.2000</td>\n      <td>485.44</td>\n      <td>485.440000</td>\n      <td>363.21</td>\n      <td>19636.79</td>\n      <td>19636.79</td>\n      <td>529.88</td>\n      <td>122.23</td>\n      <td>low_risk</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('../Resources/LoanStats_2019Q1.csv.zip')\n",
    "df = pd.read_csv(file_path, skiprows=1)[:-2]\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = df['loan_status'] != 'Issued'\n",
    "df = df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "df['int_rate'] = df['int_rate'].str.replace('%', '')\n",
    "df['int_rate'] = df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = {'Current': 'low_risk'}   \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')    \n",
    "df = df.replace(x)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = df.drop(columns=\"loan_status\")\n",
    "\n",
    "# Create our target\n",
    "y = df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          loan_amnt      int_rate  total_pymnt_inv   total_pymnt  \\\n",
       "count  96840.000000  96840.000000     96840.000000  96840.000000   \n",
       "mean   16642.454822      0.126793      1271.841045   1272.141466   \n",
       "std    10365.336053      0.048470      2795.864034   2796.006935   \n",
       "min     1000.000000      0.060000         0.000000      0.000000   \n",
       "25%     9000.000000      0.081900       407.835000    408.060000   \n",
       "50%    15000.000000      0.118000       726.530000    726.530000   \n",
       "75%    24000.000000      0.155700      1258.670000   1258.670000   \n",
       "max    40000.000000      0.308900     41418.980000  41418.981165   \n",
       "\n",
       "       total_rec_prncp  out_prncp_inv     out_prncp  last_pymnt_amnt  \\\n",
       "count     96840.000000   96840.000000  96840.000000     96840.000000   \n",
       "mean        968.178312   15667.036073  15669.991342       810.178323   \n",
       "std        2762.369001   10253.892506  10251.742002      2621.588677   \n",
       "min           0.000000       0.000000      0.000000         0.000000   \n",
       "25%         252.480000    7817.340000   7817.340000       269.480000   \n",
       "50%         461.450000   13721.910000  13721.910000       416.110000   \n",
       "75%         814.280000   22455.850000  22456.870000       673.880000   \n",
       "max       40000.000000   40000.000000  40000.000000     41409.340000   \n",
       "\n",
       "       total_rec_int  \n",
       "count   96840.000000  \n",
       "mean      303.923245  \n",
       "std       278.026566  \n",
       "min         0.000000  \n",
       "25%       109.627500  \n",
       "50%       216.410000  \n",
       "75%       408.030000  \n",
       "max      2735.400000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>total_pymnt_inv</th>\n      <th>total_pymnt</th>\n      <th>total_rec_prncp</th>\n      <th>out_prncp_inv</th>\n      <th>out_prncp</th>\n      <th>last_pymnt_amnt</th>\n      <th>total_rec_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n      <td>96840.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>16642.454822</td>\n      <td>0.126793</td>\n      <td>1271.841045</td>\n      <td>1272.141466</td>\n      <td>968.178312</td>\n      <td>15667.036073</td>\n      <td>15669.991342</td>\n      <td>810.178323</td>\n      <td>303.923245</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10365.336053</td>\n      <td>0.048470</td>\n      <td>2795.864034</td>\n      <td>2796.006935</td>\n      <td>2762.369001</td>\n      <td>10253.892506</td>\n      <td>10251.742002</td>\n      <td>2621.588677</td>\n      <td>278.026566</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1000.000000</td>\n      <td>0.060000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>9000.000000</td>\n      <td>0.081900</td>\n      <td>407.835000</td>\n      <td>408.060000</td>\n      <td>252.480000</td>\n      <td>7817.340000</td>\n      <td>7817.340000</td>\n      <td>269.480000</td>\n      <td>109.627500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>15000.000000</td>\n      <td>0.118000</td>\n      <td>726.530000</td>\n      <td>726.530000</td>\n      <td>461.450000</td>\n      <td>13721.910000</td>\n      <td>13721.910000</td>\n      <td>416.110000</td>\n      <td>216.410000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24000.000000</td>\n      <td>0.155700</td>\n      <td>1258.670000</td>\n      <td>1258.670000</td>\n      <td>814.280000</td>\n      <td>22455.850000</td>\n      <td>22456.870000</td>\n      <td>673.880000</td>\n      <td>408.030000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>40000.000000</td>\n      <td>0.308900</td>\n      <td>41418.980000</td>\n      <td>41418.981165</td>\n      <td>40000.000000</td>\n      <td>40000.000000</td>\n      <td>40000.000000</td>\n      <td>41409.340000</td>\n      <td>2735.400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "low_risk       94116\n",
       "Fully Paid      2157\n",
       "high_risk        526\n",
       "Charged Off       41\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(72630, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Create X_train, X_test, y_train, y_test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Scale the training and testing data using the `StandardScaler` from `sklearn`. Remember that when scaling the data, you only scale the features data (`X_train` and `X_testing`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "X_Scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_Scaler.transform(X_train)\n",
    "X_test_scaled = X_Scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling\n",
    "\n",
    "In this section, you will compare two oversampling algorithms to determine which algorithm results in the best performance. You will oversample the data using the naive random oversampling algorithm and the SMOTE algorithm. For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'low_risk': 70587,\n",
       "         'Charged Off': 70587,\n",
       "         'high_risk': 70587,\n",
       "         'Fully Paid': 70587})"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ROS = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ROS.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5807004122572145"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   10,     0,     0,     0],\n",
       "       [    0,   538,     0,     1],\n",
       "       [    0,     1,    86,    45],\n",
       "       [    0,    42,  8326, 15161]])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\nCharged Off       1.00      1.00      1.00      1.00      1.00      1.00        10\n Fully Paid       0.93      1.00      1.00      0.96      1.00      1.00       539\n  high_risk       0.01      0.65      0.65      0.02      0.65      0.43       132\n   low_risk       1.00      0.64      0.93      0.78      0.78      0.58     23529\n\navg / total       0.99      0.65      0.93      0.78      0.78      0.59     24210\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'low_risk': 70587,\n",
       "         'Charged Off': 70587,\n",
       "         'high_risk': 70587,\n",
       "         'Fully Paid': 70587})"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8372497443450158"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   10,     0,     0,     0],\n",
       "       [    0,   538,     0,     1],\n",
       "       [    0,     1,    93,    38],\n",
       "       [    0,    44,  8278, 15207]])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\nCharged Off       1.00      1.00      1.00      1.00      1.00      1.00        10\n Fully Paid       0.92      1.00      1.00      0.96      1.00      1.00       539\n  high_risk       0.01      0.70      0.66      0.02      0.68      0.46       132\n   low_risk       1.00      0.65      0.94      0.78      0.78      0.59     23529\n\navg / total       0.99      0.65      0.94      0.78      0.78      0.60     24210\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "\n",
    "In this section, you will test an undersampling algorithms to determine which algorithm results in the best performance compared to the oversampling algorithms above. You will undersample the data using the Cluster Centroids algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'Charged Off': 31, 'Fully Paid': 31, 'high_risk': 31, 'low_risk': 31})"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "CC = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = CC.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8372497443450158"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   10,     0,     0,     0],\n",
       "       [    0,   447,     0,    92],\n",
       "       [    0,     1,    97,    34],\n",
       "       [    0,    18, 10748, 12763]])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\nCharged Off       1.00      1.00      1.00      1.00      1.00      1.00        10\n Fully Paid       0.96      0.83      1.00      0.89      0.91      0.81       539\n  high_risk       0.01      0.73      0.55      0.02      0.64      0.41       132\n   low_risk       0.99      0.54      0.81      0.70      0.66      0.43     23529\n\navg / total       0.98      0.55      0.82      0.70      0.67      0.44     24210\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination (Over and Under) Sampling\n",
    "\n",
    "In this section, you will test a combination over- and under-sampling algorithm to determine if the algorithm results in the best performance compared to the other sampling algorithms above. You will resample the data using the SMOTEENN algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'Charged Off': 70587,\n",
       "         'Fully Paid': 70394,\n",
       "         'high_risk': 68041,\n",
       "         'low_risk': 67623})"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "sm = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7766497552737786"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   10,     0,     0,     0],\n",
       "       [    0,   539,     0,     0],\n",
       "       [    0,     2,    98,    32],\n",
       "       [    0,    44,  8229, 15256]])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\nCharged Off       1.00      1.00      1.00      1.00      1.00      1.00        10\n Fully Paid       0.92      1.00      1.00      0.96      1.00      1.00       539\n  high_risk       0.01      0.74      0.66      0.02      0.70      0.49       132\n   low_risk       1.00      0.65      0.95      0.79      0.79      0.60     23529\n\navg / total       0.99      0.66      0.95      0.79      0.79      0.61     24210\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "17768faa9740a7a627b53c0a447c29a5dec5cb382f43934531627940642b9218"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}